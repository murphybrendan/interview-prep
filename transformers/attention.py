"""
Implement self attention
"""

"""
Implement attention
(multi-head)
"""

"""
Implement flash attention
"""

"""
Self-Attention
Cross-Attention
Multi-Head Attention
Masked Self-Attention
Local Attention
Sparse Attention
Axial Attention
"""